## GaussianTalker 运行手册（当前工作状态）
vibe coding这一块
key可以直接找我要
### 当前已打通的流程
- 语音识别：上传 WAV 音频，识别文本保存到 `static/text/input.txt`。
- 大模型回复：根据识别文本生成回复，保存到 `static/text/output.txt`。
- 语音合成：将回复合成为语音，保存到 `static/audios/ai_response.wav`（使用本地 `pyttsx3`）。

### 近期关键改动
- `backend/chat_engine.py`
  - `get_ai_response(...)` 统一大模型调用逻辑，并对智谱密钥格式（`id.secret`）做了校验。
  - 安全兜底：若 LLM 调用失败，会将输入文本回显到 `output.txt`，保证后续 TTS 不中断。
- `app.py`
  - 关闭 Flask 自动重载（`use_reloader=False`），避免 Windows 上与 `pyttsx3/COM` 的重复重启问题。

### 启动步骤
1) 安装依赖（PowerShell）：
```bash
pip install -r requirements.txt
```
2) 配置环境变量（示例，仅在当前会话生效）：
```powershell
$env:ZHIPUAI_API_KEY = '你的id.你的secret'   # 调用智谱 API 所需
```
3) 启动服务：
```bash
python app.py
```
服务默认地址：http://127.0.0.1:5001

### 一次性对话接口
- 路径：`POST /chat/once`
- 表单字段：
  - `audio`：要识别的 WAV 文件
- 示例（PowerShell/curl）：
```bash
curl -F "audio=@static/audios/input.wav" http://127.0.0.1:5001/chat/once
```

### 生成的产物
- `static/text/input.txt`：识别得到的用户文本
- `static/text/output.txt`：大模型回复（或在失败时的输入回显）
- `static/audios/ai_response.wav`：将回复合成后的语音

### 环境变量
- `ZHIPUAI_API_KEY`：智谱 API Key，格式必须为 `id.secret`（不要加引号与空格）
- 模型可在代码中通过函数参数覆写（若未设置，使用默认值）

### 常见问题排查
- 报错 “invalid api_key, not enough values to unpack”：
  - 确认 `ZHIPUAI_API_KEY` 格式为 `id.secret`，无多余引号/空格。
  - 检查变量作用域：`Process`、`User`、`Machine` 是否有旧值覆盖。
- 未生成 `ai_response.wav`：
  - 查看控制台是否有 TTS 错误；检查音频设备可用性。
  - 确认 `output.txt` 是否存在；即使 LLM 失败也应看到输入回显。
- Windows 下服务频繁重启：
  - 确认 `app.py` 中已设置 `use_reloader=False`。

### 备注
- 默认从环境变量读取智谱密钥；若环境未配置，则使用函数入参作为后备。
- 整体链路具备韧性：识别 → LLM（或回显） → TTS，尽量保证全流程成功完成。


## 语音克隆
已实现功能与流程
整体逻辑（非流式）
录音→上传→ASR 识别→LLM 回复→TTS 合成→前端文本展示+音频播放
后端
ASR：
backend/chat_engine.py::audio_to_text
SpeechRecognition + Google 识别
ffmpeg 兜底将浏览器录音转为 16k/PCM16/mono
输出：static/text/input.txt
LLM：
backend/chat_engine.py::get_ai_response
智谱 ZhipuAI，同步接口
从 ZHIPUAI_API_KEY 环境变量优先读取，格式校验 id.secret
失败兜底：回显用户输入，确保流程不断
输出：
static/text/output.txt
TTS（默认）：
backend/chat_engine.py::text_to_speech
本地 pyttsx3（SAPI5），离线
输出：static/audios/ai_response.wav
语音克隆（新增）：
backend/voice_cloner.py
Coqui XTTS v2，懒加载（全局 _tts 缓存）
兼容 PyTorch 2.6+ 的安全加载：允许 XttsConfig 与 XttsAudioConfig
自动用 ffmpeg 将参考音规范化为 22.05k/单声道/PCM16
函数：
synthesize_with_clone(text, ref_audio_path, out_path, language='zh-cn')
对话管线（新增）：
backend/chat_engine.py::chat_pipeline
读取 voice_clone 表单字段
use_input：参考音为 static/audios/input.wav
cloneA/cloneB：参考音为 static/voices/cloneA.wav|cloneB.wav
若传入存在的路径，则使用该自定义参考音
先尝试语音克隆，失败自动回退 pyttsx3
返回 JSON 字段：recognized_text、ai_text、tts_audio_path、video_path
路由
/chat_system GET：渲染页面
/chat_system POST：调用 
chat_pipeline
，返回 JSON，前端自动播放音频
/save_audio POST：保存录音到 static/audios/input.wav
运行：app.run(debug=True, port=5001, use_reloader=False)
前端
templates/chat_system.html
录音器（MediaRecorder）
表单新增“语音克隆模型名称”：off/use_input/cloneA/cloneB
新增 <audio id="ttsAudio"> 播放合成音频
展示“识别文本”和“AI回复”
提交后自动播放 tts_audio_url，并刷新占位视频（可选）_
使用说明
启动
安装依赖（见下方 requirements）
设置环境变量（PowerShell）
$env:ZHIPUAI_API_KEY="id.secret"（不要包引号或空格）
确保 ffmpeg 在 PATH（用于音频规范化）
python app.py
访问 http://127.0.0.1:5001/chat_system
语音克隆
预设音色：将参考音放入
static/voices/cloneA.wav
static/voices/cloneB.wav
页面选择“预设音色 A/B”或“使用当前录音”
首次加载 XTTS v2 模型会稍慢；同进程二次请求会复用 _tts，更快
依赖与环境（requirements.txt）
我已为你提出对 
requirements.txt
 的修改建议，便于一键安装（Python 3.10/3.11 推荐）：
Flask、SpeechRecognition、zhipuai、pyttsx3、pywin32
语音克隆：TTS、transformers 固定到 4.40.2
PyTorch 固定到 2.5.1 系列（避免 PyTorch 2.6+ 的 weights_only 默认限制）
对文件的提议内容如下（请在 IDE 中应用我已提交的补丁）：
TTS==0.22.0
transformers==4.40.2
torch==2.5.1
torchvision==0.20.1
torchaudio==2.5.1
注意：

若你使用 GPU（CUDA 12.1），应通过官方索引安装对应 CUDA 版本的 torch/torchvision/torchaudio，或在 requirements 中保留 CPU 版本，之后手动升级到 CUDA 版本。
若仍在 Python 3.12，TTS 0.22.0 不支持，需用 Python 3.10 或 3.11 的环境（建议用 Anaconda Prompt 创建 gt-xtts 环境）。
常见问题与排查
大模型报“无效的 ZHIPUAI_API_KEY”
因为代码优先读环境变量。请重新设置有效的 id.secret 值，或清除环境变量让硬编码生效。
语音克隆首轮报 BeamSearchScorer ImportError
固定 transformers 到 4.40.2（已写入 requirements）。
语音克隆权重加载报 Weights only load failed / Unsupported global
我们已在 
voice_cloner.py
 中加入 add_safe_globals([XttsConfig, XttsAudioConfig])；若仍有其它类名报错，告诉我类名，我会加入白名单。
降级到 PyTorch 2.5.1（requirements 已指定）可从根本上规避。
音频无法识别
安装并配置 ffmpeg，以便从 webm/opus 转为 16k PCM WAV。
自动播放被阻止
浏览器策略所致，点 <audio> 手动播放即可。
目录与数据产物
输入/输出
static/audios/input.wav（录音）
static/text/input.txt（识别结果）
static/text/output.txt
（LLM 回复或回显）
static/audios/ai_response.wav（合成语音）
预设参考音
static/voices/cloneA.wav
static/voices/cloneB.wav