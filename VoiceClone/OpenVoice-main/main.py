# OpenVoice-main/main.py

import os
import torch
from openvoice.models_wrapper import BaseSpeakerTTS, ToneColorConverter

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ===== å®˜æ–¹ TTS æ¨¡å‹ï¼ˆå¿…é¡»æœ‰ config.jsonï¼‰=====
en_tts_dir = os.path.join(BASE_DIR, "checkpoints", "base_speakers", "EN")
zh_tts_dir = os.path.join(BASE_DIR, "checkpoints", "base_speakers", "ZH")

# ===== éŸ³è‰²è½¬æ¢æ¨¡å‹ =====
converter_dir = os.path.join(BASE_DIR, "checkpoints", "converter")

# ===== checkpoints_v2 éŸ³è‰² =====
SE_V2_DIR = os.path.join(
    BASE_DIR, "checkpoints_v2", "base_speakers", "ses"
)

device = "cuda" if torch.cuda.is_available() else "cpu"

# ===== åˆå§‹åŒ–æ¨¡å‹ =====
en_tts = BaseSpeakerTTS(
    os.path.join(en_tts_dir, "config.json"),
    device=device
)
en_tts.load_ckpt(os.path.join(en_tts_dir, "checkpoint.pth"))

zh_tts = BaseSpeakerTTS(
    os.path.join(zh_tts_dir, "config.json"),
    device=device
)
zh_tts.load_ckpt(os.path.join(zh_tts_dir, "checkpoint.pth"))

tone_converter = ToneColorConverter(
    os.path.join(converter_dir, "config.json"),
    device=device
)
tone_converter.load_ckpt(
    os.path.join(converter_dir, "checkpoint.pth")
)


# ======================================================
# å¯¹å¤–æ¥å£ï¼šç”¨ checkpoints_v2 çš„ en-default.pth åšå£°éŸ³å…‹éš†
# ======================================================
def synthesize(
    text,
    language="en",
    output_path="outputs/output.wav",
    ref_audio=None,                 # ğŸ‘ˆ æ–°å¢ï¼šå‚è€ƒéŸ³é¢‘
    v2_se_name="en-default.pth",    # ğŸ‘ˆ å…œåº•æ–¹æ¡ˆ
):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    ref_audio = os.path.join(BASE_DIR, ref_audio)
    # ===== é€‰æ‹© TTS æ¨¡å‹ =====
    if language.lower() in ["en", "english"]:
        tts_model = en_tts
        src_se = torch.load(
            os.path.join(en_tts_dir, "en_default_se.pth"),
            map_location=device
        )
        lang_flag = "english"
    elif language.lower() in ["zh", "chinese"]:
        tts_model = zh_tts
        src_se = torch.load(
            os.path.join(zh_tts_dir, "zh_default_se.pth"),
            map_location=device
        )
        lang_flag = "chinese"
    else:
        raise ValueError("Unsupported language")

    tmp_wav = output_path.replace(".wav", "_tmp.wav")

    # ===== 1ï¸âƒ£ TTS ç”ŸæˆåŸºç¡€è¯­éŸ³ =====
    speaker = list(tts_model.hps.speakers.keys())[0]
    tts_model.tts(
        text=text,
        output_path=tmp_wav,
        speaker=speaker,
        language=lang_flag,
    )

    # ===== 2ï¸âƒ£ è·å–ç›®æ ‡éŸ³è‰²ï¼ˆé‡ç‚¹ï¼‰=====
    if ref_audio is not None:
        if not os.path.isfile(ref_audio):
            raise FileNotFoundError(ref_audio)

        print(f"ğŸ¤ Using reference audio: {ref_audio}")
        tgt_se = tone_converter.extract_se(ref_audio)

    else:
        print(f"ğŸ­ Using v2 preset voice: {v2_se_name}")
        tgt_se_path = os.path.join(SE_V2_DIR, v2_se_name)
        if not os.path.isfile(tgt_se_path):
            raise FileNotFoundError(tgt_se_path)
        tgt_se = torch.load(tgt_se_path, map_location=device)

    # ===== 3ï¸âƒ£ éŸ³è‰²è½¬æ¢ =====
    tone_converter.convert(
        audio_src_path=tmp_wav,
        src_se=src_se.to(device),
        tgt_se=tgt_se.to(device),
        output_path=output_path,
    )

    os.remove(tmp_wav)
    print(f"âœ… Audio saved to {output_path}")

