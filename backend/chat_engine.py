import os
import subprocess
import speech_recognition as sr
from zhipuai import ZhipuAI
import pyttsx3
import shutil
import time
from backend.voice_cloner import synthesize_with_clone

# å°è¯•å¯¼å…¥ Whisperï¼ˆç”¨äºæœ¬åœ°è¯­éŸ³è¯†åˆ«ï¼Œä¸éœ€è¦å¤–ç½‘ï¼‰
try:
    import whisper
    WHISPER_AVAILABLE = True
    print("[backend.chat_engine] Whisper å¯ç”¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°è¯­éŸ³è¯†åˆ«")
except ImportError:
    WHISPER_AVAILABLE = False
    print("[backend.chat_engine] Whisper ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ Google è¯­éŸ³è¯†åˆ«ï¼ˆéœ€è¦å¤–ç½‘ï¼‰")

def chat_response(data):
    """
    å®æ—¶å¯¹è¯ç³»ç»Ÿï¼šASR -> LLM -> TTSï¼ˆæœ¬åœ°ï¼‰
    ç°é˜¶æ®µä»è¿”å›å ä½è§†é¢‘ï¼Œåç»­å¯æ¥å…¥è§†é¢‘ç”Ÿæˆã€‚
    """
    print("[backend.chat_engine] æ”¶åˆ°æ•°æ®ï¼š")
    for k, v in data.items():
        print(f"  {k}: {v}")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs('./static/audios', exist_ok=True)
    os.makedirs('./static/text', exist_ok=True)

    # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„å½•éŸ³ï¼‰
    input_audio = "./static/audios/input.wav"
    input_text = "./static/text/input.txt"
    recognized_text = audio_to_text(input_audio, input_text)
    if not recognized_text:
        # å½“è¯†åˆ«å¤±è´¥æ—¶ï¼Œå†™å…¥ä¸€ä¸ªé»˜è®¤æ–‡æœ¬ï¼Œé¿å…åç»­è¯»å–æ–‡ä»¶æŠ¥é”™
        fallback_text = "ä½ å¥½ï¼Œæˆ‘çš„éº¦å…‹é£éŸ³é¢‘å¯èƒ½æ— æ•ˆï¼Œè¯·ç»§ç»­ä»¥æ–‡å­—æ–¹å¼äº¤æµã€‚"
        with open(input_text, 'w', encoding='utf-8') as f:
            f.write(fallback_text)
        recognized_text = fallback_text

    # å¤§æ¨¡å‹å›ç­”
    output_text = "./static/text/output.txt"
    api_key = "59086bcdaac941d18fd92545b7417739.OSRp1IXGkA3OMKAQ"
    model = "glm-4.5-flash"
    ai_response = get_ai_response(input_text, output_text, api_key, model)

    # æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆæœ¬åœ° TTSï¼‰
    output_audio = "./static/audios/ai_response.wav"
    text_to_speech(ai_response, output_audio)

    
    video_path = os.path.join("static", "videos", "chat_response.mp4")
    print(f"[backend.chat_engine] ç”Ÿæˆè§†é¢‘è·¯å¾„ï¼š{video_path}")
    return video_path

def chat_pipeline(data):
    os.makedirs('./static/audios', exist_ok=True)
    os.makedirs('./static/text', exist_ok=True)

    input_audio = "./static/audios/input.wav"
    input_text = "./static/text/input.txt"
    recognized_text = audio_to_text(input_audio, input_text)
    
    # ğŸš« ç¦ç”¨å…œåº•é€»è¾‘ï¼šè¯­éŸ³è¯†åˆ«å¿…é¡»æˆåŠŸæ‰ç»§ç»­
    if not recognized_text:
        raise Exception("è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼šæ— æ³•è¯†åˆ«éŸ³é¢‘å†…å®¹ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æˆ–ä¸Šä¼ æœ‰æ•ˆéŸ³é¢‘æ–‡ä»¶")

    output_text = "./static/text/output.txt"
    api_key = "59086bcdaac941d18fd92545b7417739.OSRp1IXGkA3OMKAQ"
    model = "glm-4-flash"
    ai_response = get_ai_response(input_text, output_text, api_key, model)
    
    # ğŸš« ç¦ç”¨å…œåº•é€»è¾‘ï¼šå¤§æ¨¡å‹å¿…é¡»æˆåŠŸå“åº”æ‰ç»§ç»­
    if not ai_response or ai_response.strip() == "":
        raise Exception("å¤§æ¨¡å‹å“åº”å¤±è´¥ï¼šæœªèƒ½è·å–æœ‰æ•ˆå›å¤ï¼Œè¯·æ£€æŸ¥APIé…ç½®")

    # é€‰æ‹©TTSï¼šå¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘å°±ä½¿ç”¨è¯­éŸ³å…‹éš†ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤TTS
    output_audio = "./static/audios/ai_response.wav"
    tts_audio_path = None

    # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†å‚è€ƒéŸ³é¢‘ï¼ˆç”¨äºè¯­éŸ³å…‹éš†ï¼‰
    ref_audio_path = data.get('ref_audio', '').strip() if isinstance(data, dict) else ''
    
    print(f"[backend.chat_engine] ğŸ” æ£€æŸ¥å‚è€ƒéŸ³é¢‘å‚æ•°: ref_audio='{ref_audio_path}'")
    
    if ref_audio_path and os.path.exists(ref_audio_path):
        print(f"[backend.chat_engine] âœ… ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†: {ref_audio_path}")
        try:
            tts_audio_path = synthesize_with_clone(ai_response, ref_audio_path, output_audio, language='zh')
        except Exception as e:
            print(f"[backend.chat_engine] è¯­éŸ³å…‹éš†å¤±è´¥ï¼Œå°†å›é€€åˆ°æœ¬åœ°TTSã€‚åŸå› : {e}")
            import traceback
            traceback.print_exc()
    else:
        print("[backend.chat_engine] æœªæä¾›å‚è€ƒéŸ³é¢‘ï¼Œä½¿ç”¨é»˜è®¤TTS")

    if not tts_audio_path:
        tts_audio_path = text_to_speech(ai_response, output_audio)

    # ==== æ–°å¢ï¼šGaussianTalkeræ•°å­—äººè§†é¢‘ç”Ÿæˆ ====
    video_path = os.path.join("static", "videos", "chat_response.mp4")
    
    # è·å–æ•°å­—äººæ¨¡å‹å‚æ•°
    model_name = data.get('model_name', '')  # e.g., "GaussianTalker" or "SyncTalk"
    model_param = data.get('model_param', '')  # e.g., "obama"
    
    # å¦‚æœé€‰æ‹©äº†æ•°å­—äººæ¨¡å‹å¹¶æä¾›äº†æ¨¡å‹ç›®å½•ï¼Œåˆ™ç”Ÿæˆæ•°å­—äººè§†é¢‘
    if model_name and model_param and tts_audio_path and os.path.exists(tts_audio_path):
        print(f"[backend.chat_engine] å¼€å§‹ç”Ÿæˆæ•°å­—äººè§†é¢‘ï¼šæ¨¡å‹={model_name}, ç›®å½•={model_param}")
        try:
            from backend.video_generator import generate_video
            
            # æ„é€ ä¼ é€’ç»™generate_videoçš„æ•°æ®
            # ğŸ”¥ å®æ—¶å¯¹è¯éŸ³é¢‘å¾ˆçŸ­ï¼Œé™ä½batch_sizeé¿å…OOM
            video_gen_data = {
                "model_name": model_name,
                "model_param": model_param,
                "ref_audio": tts_audio_path,
                "gpu_choice": data.get('gpu_choice', 'GPU0'),
                "batch_size": data.get('batch_size', '16'),  # é»˜è®¤é™ä½åˆ°16
                "iteration": data.get('iteration', '10000'),
                "ssh_host": data.get('ssh_host', 'connect.bjb1.seetacloud.com'),
                "ssh_port": data.get('ssh_port', 40258),
                "ssh_password": data.get('ssh_password', '83WncIL5CoYB')
            }
            
            video_gen_result = generate_video(video_gen_data)
            
            # generate_videoè¿”å›çš„æ˜¯è§†é¢‘è·¯å¾„å­—ç¬¦ä¸²
            if video_gen_result and isinstance(video_gen_result, str) and os.path.exists(video_gen_result):
                video_path = video_gen_result
                print(f"[backend.chat_engine] æ•°å­—äººè§†é¢‘ç”ŸæˆæˆåŠŸï¼š{video_path}")
            else:
                print(f"[backend.chat_engine] æ•°å­—äººè§†é¢‘ç”Ÿæˆå¤±è´¥æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼š{video_gen_result}")
                # å¤±è´¥æ—¶ä½¿ç”¨å ä½è§†é¢‘ï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
                
        except Exception as e:
            print(f"[backend.chat_engine] æ•°å­—äººè§†é¢‘ç”Ÿæˆå¼‚å¸¸ï¼š{e}")
            import traceback
            traceback.print_exc()
            # å¼‚å¸¸æ—¶ä½¿ç”¨å ä½è§†é¢‘ï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
    else:
        print("[backend.chat_engine] æœªå¯ç”¨æ•°å­—äººè§†é¢‘ç”Ÿæˆï¼ˆæœªé€‰æ‹©æ¨¡å‹æˆ–éŸ³é¢‘ä¸å¯ç”¨ï¼‰")
    
    return {
        "recognized_text": recognized_text,
        "ai_text": ai_response,
        "tts_audio_path": tts_audio_path if tts_audio_path else (output_audio if os.path.exists(output_audio) else None),
        "video_path": video_path,
    }

def _ffmpeg_convert_to_pcm16_mono_16k(src_path, dst_path):
    """å°è¯•ç”¨ ffmpeg è½¬ä¸º 16k/16bit mono PCM WAVã€‚è¿”å› True/Falseã€‚"""
    try:
        cmd = [
            'ffmpeg', '-y', '-i', src_path,
            '-ac', '1', '-ar', '16000', '-c:a', 'pcm_s16le',
            dst_path
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if result.returncode == 0 and os.path.exists(dst_path) and os.path.getsize(dst_path) > 0:
            print('[backend.chat_engine] å·²ä½¿ç”¨ ffmpeg è§„èŒƒåŒ–éŸ³é¢‘ä¸º PCM16 mono 16k')
            return True
        else:
            print('[backend.chat_engine] ffmpeg è½¬ç å¤±è´¥:', result.stderr[-500:])
            return False
    except FileNotFoundError:
        print('[backend.chat_engine] æœªæ‰¾åˆ° ffmpegï¼Œè¯·å®‰è£…æˆ–åŠ å…¥ PATH åå†è¯•')
        return False
    except Exception as e:
        print('[backend.chat_engine] ffmpeg è°ƒç”¨å¼‚å¸¸:', e)
        return False


def audio_to_text(input_audio, input_text):
    """
    ä½¿ç”¨ Whisper æœ¬åœ°æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆæ— éœ€å¤–ç½‘ï¼‰
    ä¼˜å…ˆä½¿ç”¨ Whisperï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ° Google è¯†åˆ«
    """
    try:
        if WHISPER_AVAILABLE:
            # ä½¿ç”¨ Whisper æœ¬åœ°æ¨¡å‹
            print("[backend.chat_engine] ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
            
            # è®¾ç½®æ¨¡å‹ä¸‹è½½è·¯å¾„åˆ°é¡¹ç›®ç›®å½•ï¼ˆéCç›˜ï¼‰
            model_cache_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'whisper_models')
            os.makedirs(model_cache_dir, exist_ok=True)
            print(f"[backend.chat_engine] Whisper æ¨¡å‹ç¼“å­˜ç›®å½•: {model_cache_dir}")
            
            # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨ medium æ¨¡å‹ï¼Œå‡†ç¡®ç‡å¾ˆé«˜ï¼Œçº¦769MBï¼‰
            # å¯é€‰æ¨¡å‹ï¼štiny(39M), base(74M), small(244M), medium(769M, æ¨è), large(1550M)
            model = whisper.load_model("medium", download_root=model_cache_dir)
            
            # è¯†åˆ«éŸ³é¢‘ï¼Œæ·»åŠ ä¼˜åŒ–å‚æ•°
            result = model.transcribe(
                input_audio, 
                language='zh',           # æŒ‡å®šä¸­æ–‡
                initial_prompt="ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„å¥å­ã€‚",  # æç¤ºè¯ï¼Œæé«˜ä¸­æ–‡è¯†åˆ«ç‡
                temperature=0.0,         # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
                compression_ratio_threshold=2.4,
                logprob_threshold=-1.0,
                no_speech_threshold=0.6,
                beam_size=5,            # ä½¿ç”¨æŸæœç´¢ï¼Œæé«˜å‡†ç¡®ç‡
                best_of=5               # ä»å¤šä¸ªå€™é€‰ä¸­é€‰æ‹©æœ€ä½³ç»“æœ
            )
            text = result["text"].strip()
            
            if not text:
                print("[backend.chat_engine] Whisper è¯†åˆ«ç»“æœä¸ºç©º")
                return None
            
            # ä¿å­˜ç»“æœ
            with open(input_text, 'w', encoding='utf-8') as f:
                f.write(text)
            
            print(f"è¯­éŸ³è¯†åˆ«å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {input_text}")
            print(f"è¯†åˆ«ç»“æœ: {text}")
            return text
        else:
            # å›é€€åˆ° Google è¯­éŸ³è¯†åˆ«ï¼ˆéœ€è¦å¤–ç½‘ï¼‰
            print("[backend.chat_engine] Whisper ä¸å¯ç”¨ï¼Œä½¿ç”¨ Google è¯­éŸ³è¯†åˆ«ï¼ˆéœ€è¦ç½‘ç»œï¼‰...")
            recognizer = sr.Recognizer()
            
            def _recognize_from_file(path):
                with sr.AudioFile(path) as source:
                    recognizer.adjust_for_ambient_noise(source)
                    audio_data = recognizer.record(source)
                    print("æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
                    return recognizer.recognize_google(audio_data, language='zh-CN')

            # ç¬¬ä¸€æ¬¡å°è¯•ç›´æ¥è¯»å–
            try:
                text = _recognize_from_file(input_audio)
            except Exception as e:
                print('[backend.chat_engine] ç›´æ¥è¯»å–éŸ³é¢‘å¤±è´¥ï¼Œå°†å°è¯•è½¬ç ã€‚åŸå› :', e)
                tmp_converted = os.path.join(os.path.dirname(input_audio), '__converted_tmp__.wav')
                if _ffmpeg_convert_to_pcm16_mono_16k(input_audio, tmp_converted):
                    text = _recognize_from_file(tmp_converted)
                    try:
                        os.remove(tmp_converted)
                    except Exception:
                        pass
                else:
                    raise
            
            # ä¿å­˜ç»“æœ
            with open(input_text, 'w', encoding='utf-8') as f:
                f.write(text)
            print(f"è¯­éŸ³è¯†åˆ«å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {input_text}")
            print(f"è¯†åˆ«ç»“æœ: {text}")
            return text
            
    except sr.UnknownValueError:
        print("æ— æ³•è¯†åˆ«éŸ³é¢‘å†…å®¹")
        return None
    except sr.RequestError as e:
        print(f"è¯­éŸ³è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
        return None
    except FileNotFoundError:
        print(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_audio}")
        return None
    except Exception as e:
        print(f"è¯­éŸ³è¯†åˆ«å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

def get_ai_response(input_text, output_text, api_key, model):
    try:
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–å¯†é’¥ï¼Œè‹¥æ— åˆ™ä½¿ç”¨ä¼ å…¥å€¼
        api_key_env = os.getenv('ZHIPUAI_API_KEY')
        api_key_eff = (api_key_env if api_key_env else api_key or '').strip()
        # å…³é”®æ ¡éªŒï¼šæ™ºè°±å¯†é’¥ä¸€èˆ¬ä¸º "{id}.{secret}" ä¸¤æ®µå½¢å¼
        if '.' not in api_key_eff or len(api_key_eff.split('.')) != 2:
            raise ValueError("æ— æ•ˆçš„ ZHIPUAI_API_KEYï¼šåº”ä¸º id.secret çš„ä¸¤æ®µå½¢å¼ï¼Œä¸”ä¸è¦åŒ…å«å¼•å·/ç©ºæ ¼")
        client = ZhipuAI(api_key=api_key_eff)
        with open(input_text, 'r', encoding='utf-8') as file:
            content = file.read().strip()

        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼Œé™åˆ¶å›å¤é•¿åº¦
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ•°å­—äººæ¨¡å‹ï¼Œæ­£åœ¨è¿›è¡Œå®æ—¶å¯¹è¯ã€‚è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

1. èº«ä»½è®¤åŒï¼šç”¨æˆ·å¯èƒ½ä¼šæåŠä½ çš„èº«ä»½ï¼ˆå¦‚ï¼š"ä½ æ˜¯å¥¥å·´é©¬"ã€"ä½ æ˜¯æŸæŸæ˜æ˜Ÿ"ï¼‰ï¼Œä½ ä¸åº”è¯¥å¦è®¤è¿™ä¸ªèº«ä»½ï¼Œè¦è‡ªç„¶åœ°æ¥å—å¹¶æ‰®æ¼”è¿™ä¸ªè§’è‰²ã€‚

2. ä¸ªäººåå¥½ï¼šå½“è¢«é—®åŠåå¥½ã€å–œå¥½æ—¶ï¼Œä½ å¿…é¡»ç»™å‡ºå…·ä½“çš„ç­”æ¡ˆã€‚å¦‚æœä½ çŸ¥é“æ‰€æ‰®æ¼”è§’è‰²çš„çœŸå®åå¥½ï¼Œè¯·ä½¿ç”¨çœŸå®åå¥½ï¼›å¦‚æœä¸çŸ¥é“ï¼Œè¯·åˆç†ç¼–é€ ä¸€ä¸ªç¬¦åˆè§’è‰²è®¾å®šçš„åå¥½ã€‚ç»å¯¹ä¸èƒ½å›ç­”"æˆ‘æ˜¯AIï¼Œæ²¡æœ‰åå¥½"æˆ–ç±»ä¼¼çš„æ¨è„±ã€‚

3. å›å¤é£æ ¼ï¼šç”¨ç®€æ´ã€è‡ªç„¶ã€å£è¯­åŒ–çš„è¯­è¨€å›ç­”ï¼Œå›å¤æ§åˆ¶åœ¨ä¸‰å¥è¯ä»¥å†…ï¼Œä¿æŒå¯¹è¯è½»æ¾å‹å¥½ã€‚

4. è§’è‰²ä¸€è‡´æ€§ï¼šåœ¨æ•´ä¸ªå¯¹è¯è¿‡ç¨‹ä¸­ä¿æŒè§’è‰²çš„ä¸€è‡´æ€§ï¼Œä¸è¦æ‰“ç ´è§’è‰²è®¾å®šã€‚"""
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": content}
            ]
        )
        output = response.choices[0].message.content

        with open(output_text, 'w', encoding='utf-8') as file:
            file.write(output)

        print(f"ç­”å¤å·²ä¿å­˜åˆ°: {output_text}")
        return output
    except Exception as e:
        # å¤±è´¥å…œåº•ï¼šç›´æ¥æŠŠç”¨æˆ·æ–‡æœ¬å›å£°ï¼Œé¿å…æ•´ä½“ 500
        print(f"[backend.chat_engine] è°ƒç”¨å¤§æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨å…œåº•å›å¤ã€‚åŸå› : {e}")
        try:
            with open(input_text, 'r', encoding='utf-8') as f:
                fallback = f.read().strip()
            if not fallback:
                fallback = "æŠ±æ­‰ï¼Œç›®å‰æ— æ³•è¿æ¥å¤§æ¨¡å‹æœåŠ¡ã€‚"
        except Exception:
            fallback = "æŠ±æ­‰ï¼Œç›®å‰æ— æ³•è¿æ¥å¤§æ¨¡å‹æœåŠ¡ã€‚"
        try:
            with open(output_text, 'w', encoding='utf-8') as f:
                f.write(fallback)
        except Exception:
            pass
        return fallback

def text_to_speech(text, output_audio_path):
    """
    ä½¿ç”¨æœ¬åœ° TTS å¼•æ“ï¼ˆpyttsx3ï¼‰å°†æ–‡æœ¬åˆæˆä¸ºè¯­éŸ³æ–‡ä»¶ã€‚
    Windows é»˜è®¤ä½¿ç”¨ SAPI5ï¼Œæ— éœ€è”ç½‘ã€‚
    """
    try:
        if not text:
            print("[backend.chat_engine] TTS è·³è¿‡ï¼šæ–‡æœ¬ä¸ºç©º")
            return None

        os.makedirs(os.path.dirname(output_audio_path), exist_ok=True)

        engine = pyttsx3.init()
        # åŸºç¡€å‚æ•°å¯æŒ‰éœ€è°ƒæ•´
        engine.setProperty('rate', 160)
        engine.setProperty('volume', 0.9)

        engine.save_to_file(text, output_audio_path)
        engine.runAndWait()

        print(f"[backend.chat_engine] è¯­éŸ³åˆæˆæˆåŠŸ: {output_audio_path}")
        return output_audio_path
    except Exception as e:
        print(f"[backend.chat_engine] TTS é”™è¯¯: {e}")
        return None